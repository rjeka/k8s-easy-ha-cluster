
#Add directory for cert
- name: Add tmp directory
  hosts: localhost
  gather_facts: no

  tasks:
    - name: create temp cert directory
      file:
        path: /tmp/k8s
        state: directory
        force: yes


# Installing Kubernetes
- name: Installing shared packages and Kubernetes for the masters and work nodes
  hosts: [masters, worknodes, ingressnodes ]
  become: yes
  become_method: sudo

  tasks:
    - name: Install kubernetes
      include_role:
        name: kubelet


#Installing CRI - conainerd or docker
- name: Installing CRI
  hosts: [masters, worknodes, ingressnodes]
  become: yes
  become_method: sudo

  tasks:
    - name: enable ip_forward
      sysctl:
        name: net.ipv4.ip_forward
        value: 1

    - name: Entry DNS name node in /etc/hosts
      lineinfile:
        path: /etc/hosts
        line: '{{ansible_host}} {{ansible_hostname}}'

    - name: Install docker
      include_role:
        name: docker
      when: criType == "docker"

    - name: Install containerd
      include_role:
        name: containerd
      when: criType == "containerd"


#Install the soft that is only needed on the masters
- name: Setting Up kubernetes masters
  hosts: masters
  become: yes
  become_method: sudo

  tasks:
    - name: Install etcd and keepalived
      include_role:
        name: "{{ item }}"
      with_items:
      - etcd
      - keepalived

    - name: Install nginx
      include_role:
        name: nginx
      when: apiLoadBalancer == "master"


#Init First master
- name: Init first cluster master
  hosts: master1
  become: yes
  become_method: sudo

  tasks:
    - name: install git
      apt:
        name: git

    - name: Reset Old Cluster and del docker containers
      shell: |
        kubeadm reset --force
      when: criType == "docker"

    - name: Reset Old Cluster and del crictl containers
      shell: |
        kubeadm reset --force --cri-socket /run/containerd/containerd.sock
      when: criType == "containerd"

    - name: Init First master {{ansible_hostname}}
      include_role:
        name: initMaster


- name: Init other masters
  hosts: [ master2, master3 ]
  become: yes
  become_method: sudo

  tasks:
    - name: Reset Old Cluster and del docker containers
      shell: |
        kubeadm reset --force
      when: criType == "docker"

    - name: Reset Old Cluster and del crictl containers
      shell: |
        kubeadm reset --force --cri-socket /run/containerd/containerd.sock
      when: criType == "containerd"

    - name: Create PKI directory
      file:
        path: /etc/kubernetes/pki/
        state: directory
        group: root
        owner: root
        force: yes

    - name: copy certificate
      copy:
        src:  /tmp/k8s/master1/etc/kubernetes/pki/
        dest: /etc/kubernetes/pki/

    - name: init {{ansible_hostname}}
      include_role:
        name: initMaster

- name: Scale DNS to 2nd and 3rd master
  hosts: master1
  gather_facts: no

  tasks:
    - name: Pause while callico starts
      pause:
        prompt: "Wait starting CIDR and Kubernetes coredns"
        seconds: 15

    - name: Scale DNS
      shell: |
        kubectl scale --replicas=4 -n kube-system deployment/coredns
      become: false


- name: Change API IP address
  hosts: master1

  tasks:
  - include_tasks: tasks/ÑhangeAPI.yml
    when: apiLoadBalancer == "master"


- name: Add worknodes in cluster
  hosts: [ worknodes, ingressnodes ]
  become: yes
  become_method: sudo

  tasks:
    - name: add node to Cluster
      include_role:
        name: addWorkNode


- name: Label ingress nodes
  hosts: master1

  vars:
    HOST_COUNT: "{{ groups['ingressnodes'] | length }}"

  tasks:
    - name:  Get gather_facts in ingressnodes
      setup:
      delegate_to: "{{item}}"
      delegate_facts: True
      with_items: "{{groups.ingressnodes}}"

    - name: Add label to ingress nodes
      shell: |
        {% for HOST_NUMBER in range(groups['ingressnodes'] | length ) %}
          kubectl label nodes {{hostvars[groups['ingressnodes'][HOST_NUMBER]]['ansible_hostname']}} nodeType=ingress
        {% endfor %}
      when:  HOST_COUNT > "0"


- name: Install ingress controller
  hosts: master1
  gather_facts: no

  vars:
    HOST_COUNT: "{{ groups['ingressnodes'] | length }}"

  tasks:
    - name: Install ingress controller
      include_role:
        name: ingress


- name: Deploy Kubernetes dashboard ans heapster
  hosts: master1
  become: yes
  become_method: sudo

  tasks:
    - name: Install dashboard
      include_role:
        name: dashboard

    - name: Install heapster
      include_role:
        name: heapster


- name: Install Helm
  hosts: master1

  tasks:
    - name: Install Helm
      include_role:
        name: helm
      when: helm == "true"


- name: Garbage collection
  hosts: all

  tasks:
    - name: Delete downloaded files
      file:
        path: "{{ item }}"
        state: absent
      with_items:
      - /opt/archives
      - /opt/config/dashboard
      - /opt/config/heapster
      - /opt/config/kube-proxy.txt
      - /opt/config/rbac-config.yaml
      - /opt/config/helm.sh
      - /opt/config/mandatory.yaml
      - /opt/config/service-nodeport.yaml
      when:
        - inventory_hostname == "master1"
        - garbageCollection == "true"
      become: true

    - name:  del local certificate
      file:
        path: /tmp/k8s/
        state: absent
      when:
        - inventory_hostname == "localhost"
        - garbageCollection == "true"

- name: Cluster info
  hosts: master1
  become: yes
  become_method: sudo

  tasks:
    - name: Get kubeadmin token
      shell: |
        cat /opt/config/token.txt
      register: kubeadmToken

    - name: Get Dashboard admin token
      shell: |
        kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk '{print $1}') | grep token:
      register: dashboardToken
      become: false

    - name: Print Cluster info
      debug:
        msg: [
          "To enter new work nodes into the cluster, use the following command:",
          "{{ kubeadmToken.stdout }}",
          "Dashboard is available at: https://{{virtIp}}:30443",
          "Admin {{dashboardToken.stdout}}"
          ]
